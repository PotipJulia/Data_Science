{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>team_1</th>\n",
       "      <th>team_2</th>\n",
       "      <th>home</th>\n",
       "      <th>seed_diff</th>\n",
       "      <th>score_diff</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985</td>\n",
       "      <td>288</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-9</td>\n",
       "      <td>41</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985</td>\n",
       "      <td>5929</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>61</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>9884</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-4</td>\n",
       "      <td>59</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985</td>\n",
       "      <td>73</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>3920</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>54</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  team_1  team_2  home  seed_diff  score_diff  score_1  score_2  won\n",
       "0    1985     288      73     0         -3          -9       41       50    0\n",
       "1    1985    5929      73     0          4           6       61       55    1\n",
       "2    1985    9884      73     0          5          -4       59       63    0\n",
       "3    1985      73     288     0          3           9       50       41    1\n",
       "4    1985    3920     410     0          1          -9       54       63    0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_tourney=pd.read_csv('datasets_495447_920088_games_tourney.csv')\n",
    "games_tourney_train=games_tourney[:3500]\n",
    "games_tourney_test=games_tourney[3500:4200]\n",
    "games_tourney_pred=games_tourney[4200:]\n",
    "games_tourney_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=games_tourney_train[['seed_diff']]\n",
    "y_regr=games_tourney_train[['score_diff']]\n",
    "y_class=games_tourney_train[['won']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor=Input((1,))\n",
    "output_tensor_regr=Dense(1)(input_tensor)\n",
    "output_tensor_class=Dense(1, activation='sigmoid')(output_tensor_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(input_tensor,[output_tensor_regr,output_tensor_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=['mean_absolute_error', 'binary_crossentropy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "110/110 [==============================] - 0s 619us/step - loss: 21.5107 - dense_8_loss: 16.2174 - dense_9_loss: 5.2933\n",
      "Epoch 2/150\n",
      "110/110 [==============================] - 0s 674us/step - loss: 19.9913 - dense_8_loss: 15.6946 - dense_9_loss: 4.2967\n",
      "Epoch 3/150\n",
      "110/110 [==============================] - 0s 628us/step - loss: 18.6371 - dense_8_loss: 15.1887 - dense_9_loss: 3.4483\n",
      "Epoch 4/150\n",
      "110/110 [==============================] - 0s 609us/step - loss: 17.4521 - dense_8_loss: 14.7050 - dense_9_loss: 2.7472\n",
      "Epoch 5/150\n",
      "110/110 [==============================] - 0s 597us/step - loss: 16.4347 - dense_8_loss: 14.2534 - dense_9_loss: 2.1813\n",
      "Epoch 6/150\n",
      "110/110 [==============================] - 0s 591us/step - loss: 15.5626 - dense_8_loss: 13.8261 - dense_9_loss: 1.7365\n",
      "Epoch 7/150\n",
      "110/110 [==============================] - 0s 571us/step - loss: 14.8222 - dense_8_loss: 13.4231 - dense_9_loss: 1.3991\n",
      "Epoch 8/150\n",
      "110/110 [==============================] - 0s 571us/step - loss: 14.2012 - dense_8_loss: 13.0464 - dense_9_loss: 1.1548\n",
      "Epoch 9/150\n",
      "110/110 [==============================] - 0s 616us/step - loss: 13.6783 - dense_8_loss: 12.6977 - dense_9_loss: 0.9806\n",
      "Epoch 10/150\n",
      "110/110 [==============================] - 0s 653us/step - loss: 13.2331 - dense_8_loss: 12.3757 - dense_9_loss: 0.8574\n",
      "Epoch 11/150\n",
      "110/110 [==============================] - 0s 575us/step - loss: 12.8422 - dense_8_loss: 12.0742 - dense_9_loss: 0.7680\n",
      "Epoch 12/150\n",
      "110/110 [==============================] - 0s 604us/step - loss: 12.4904 - dense_8_loss: 11.7901 - dense_9_loss: 0.7003\n",
      "Epoch 13/150\n",
      "110/110 [==============================] - 0s 580us/step - loss: 12.1538 - dense_8_loss: 11.5069 - dense_9_loss: 0.6470\n",
      "Epoch 14/150\n",
      "110/110 [==============================] - 0s 588us/step - loss: 11.8397 - dense_8_loss: 11.2340 - dense_9_loss: 0.6057\n",
      "Epoch 15/150\n",
      "110/110 [==============================] - 0s 592us/step - loss: 11.5594 - dense_8_loss: 10.9839 - dense_9_loss: 0.5755\n",
      "Epoch 16/150\n",
      "110/110 [==============================] - 0s 587us/step - loss: 11.3160 - dense_8_loss: 10.7587 - dense_9_loss: 0.5573\n",
      "Epoch 17/150\n",
      "110/110 [==============================] - 0s 588us/step - loss: 11.1052 - dense_8_loss: 10.5567 - dense_9_loss: 0.5485\n",
      "Epoch 18/150\n",
      "110/110 [==============================] - 0s 585us/step - loss: 10.9168 - dense_8_loss: 10.3707 - dense_9_loss: 0.5461\n",
      "Epoch 19/150\n",
      "110/110 [==============================] - 0s 585us/step - loss: 10.7574 - dense_8_loss: 10.2082 - dense_9_loss: 0.5492\n",
      "Epoch 20/150\n",
      "110/110 [==============================] - 0s 582us/step - loss: 10.6167 - dense_8_loss: 10.0631 - dense_9_loss: 0.5536\n",
      "Epoch 21/150\n",
      "110/110 [==============================] - 0s 585us/step - loss: 10.4853 - dense_8_loss: 9.9275 - dense_9_loss: 0.5578\n",
      "Epoch 22/150\n",
      "110/110 [==============================] - 0s 684us/step - loss: 10.3664 - dense_8_loss: 9.8048 - dense_9_loss: 0.5616\n",
      "Epoch 23/150\n",
      "110/110 [==============================] - 0s 590us/step - loss: 10.2644 - dense_8_loss: 9.7013 - dense_9_loss: 0.5631\n",
      "Epoch 24/150\n",
      "110/110 [==============================] - 0s 625us/step - loss: 10.1704 - dense_8_loss: 9.6085 - dense_9_loss: 0.5618\n",
      "Epoch 25/150\n",
      "110/110 [==============================] - 0s 600us/step - loss: 10.0855 - dense_8_loss: 9.5264 - dense_9_loss: 0.5591\n",
      "Epoch 26/150\n",
      "110/110 [==============================] - 0s 583us/step - loss: 10.0064 - dense_8_loss: 9.4507 - dense_9_loss: 0.5557\n",
      "Epoch 27/150\n",
      "110/110 [==============================] - 0s 554us/step - loss: 9.9339 - dense_8_loss: 9.3814 - dense_9_loss: 0.5525\n",
      "Epoch 28/150\n",
      "110/110 [==============================] - 0s 557us/step - loss: 9.8693 - dense_8_loss: 9.3197 - dense_9_loss: 0.5496\n",
      "Epoch 29/150\n",
      "110/110 [==============================] - 0s 570us/step - loss: 9.8144 - dense_8_loss: 9.2662 - dense_9_loss: 0.5482\n",
      "Epoch 30/150\n",
      "110/110 [==============================] - 0s 585us/step - loss: 9.7703 - dense_8_loss: 9.2232 - dense_9_loss: 0.5471\n",
      "Epoch 31/150\n",
      "110/110 [==============================] - 0s 569us/step - loss: 9.7299 - dense_8_loss: 9.1833 - dense_9_loss: 0.5466\n",
      "Epoch 32/150\n",
      "110/110 [==============================] - 0s 548us/step - loss: 9.7098 - dense_8_loss: 9.1634 - dense_9_loss: 0.5463\n",
      "Epoch 33/150\n",
      "110/110 [==============================] - 0s 578us/step - loss: 9.6937 - dense_8_loss: 9.1474 - dense_9_loss: 0.5463\n",
      "Epoch 34/150\n",
      "110/110 [==============================] - 0s 559us/step - loss: 9.6778 - dense_8_loss: 9.1315 - dense_9_loss: 0.5463\n",
      "Epoch 35/150\n",
      "110/110 [==============================] - 0s 559us/step - loss: 9.6649 - dense_8_loss: 9.1187 - dense_9_loss: 0.5462\n",
      "Epoch 36/150\n",
      "110/110 [==============================] - 0s 578us/step - loss: 9.6553 - dense_8_loss: 9.1092 - dense_9_loss: 0.5462\n",
      "Epoch 37/150\n",
      "110/110 [==============================] - 0s 562us/step - loss: 9.6485 - dense_8_loss: 9.1022 - dense_9_loss: 0.5464\n",
      "Epoch 38/150\n",
      "110/110 [==============================] - 0s 584us/step - loss: 9.6434 - dense_8_loss: 9.0972 - dense_9_loss: 0.5463\n",
      "Epoch 39/150\n",
      "110/110 [==============================] - 0s 662us/step - loss: 9.6407 - dense_8_loss: 9.0943 - dense_9_loss: 0.5463\n",
      "Epoch 40/150\n",
      "110/110 [==============================] - 0s 693us/step - loss: 9.6393 - dense_8_loss: 9.0929 - dense_9_loss: 0.5463\n",
      "Epoch 41/150\n",
      "110/110 [==============================] - 0s 570us/step - loss: 9.6380 - dense_8_loss: 9.0918 - dense_9_loss: 0.5463\n",
      "Epoch 42/150\n",
      "110/110 [==============================] - 0s 551us/step - loss: 9.6365 - dense_8_loss: 9.0903 - dense_9_loss: 0.5462\n",
      "Epoch 43/150\n",
      "110/110 [==============================] - 0s 553us/step - loss: 9.6359 - dense_8_loss: 9.0897 - dense_9_loss: 0.5462\n",
      "Epoch 44/150\n",
      "110/110 [==============================] - 0s 566us/step - loss: 9.6356 - dense_8_loss: 9.0894 - dense_9_loss: 0.5463\n",
      "Epoch 45/150\n",
      "110/110 [==============================] - 0s 550us/step - loss: 9.6351 - dense_8_loss: 9.0888 - dense_9_loss: 0.5462\n",
      "Epoch 46/150\n",
      "110/110 [==============================] - 0s 556us/step - loss: 9.6354 - dense_8_loss: 9.0889 - dense_9_loss: 0.5465\n",
      "Epoch 47/150\n",
      "110/110 [==============================] - 0s 563us/step - loss: 9.6345 - dense_8_loss: 9.0881 - dense_9_loss: 0.5464\n",
      "Epoch 48/150\n",
      "110/110 [==============================] - 0s 602us/step - loss: 9.6337 - dense_8_loss: 9.0875 - dense_9_loss: 0.5462\n",
      "Epoch 49/150\n",
      "110/110 [==============================] - 0s 578us/step - loss: 9.6336 - dense_8_loss: 9.0873 - dense_9_loss: 0.5462\n",
      "Epoch 50/150\n",
      "110/110 [==============================] - 0s 634us/step - loss: 9.6332 - dense_8_loss: 9.0871 - dense_9_loss: 0.5461\n",
      "Epoch 51/150\n",
      "110/110 [==============================] - 0s 585us/step - loss: 9.6333 - dense_8_loss: 9.0870 - dense_9_loss: 0.5463\n",
      "Epoch 52/150\n",
      "110/110 [==============================] - 0s 573us/step - loss: 9.6331 - dense_8_loss: 9.0867 - dense_9_loss: 0.5463\n",
      "Epoch 53/150\n",
      "110/110 [==============================] - 0s 574us/step - loss: 9.6327 - dense_8_loss: 9.0864 - dense_9_loss: 0.5463\n",
      "Epoch 54/150\n",
      "110/110 [==============================] - 0s 546us/step - loss: 9.6330 - dense_8_loss: 9.0866 - dense_9_loss: 0.5463\n",
      "Epoch 55/150\n",
      "110/110 [==============================] - 0s 572us/step - loss: 9.6334 - dense_8_loss: 9.0870 - dense_9_loss: 0.5464\n",
      "Epoch 56/150\n",
      "110/110 [==============================] - 0s 564us/step - loss: 9.6330 - dense_8_loss: 9.0866 - dense_9_loss: 0.5464\n",
      "Epoch 57/150\n",
      "110/110 [==============================] - 0s 551us/step - loss: 9.6326 - dense_8_loss: 9.0864 - dense_9_loss: 0.5462\n",
      "Epoch 58/150\n",
      "110/110 [==============================] - 0s 541us/step - loss: 9.6326 - dense_8_loss: 9.0863 - dense_9_loss: 0.5463\n",
      "Epoch 59/150\n",
      "110/110 [==============================] - 0s 535us/step - loss: 9.6329 - dense_8_loss: 9.0867 - dense_9_loss: 0.5462\n",
      "Epoch 60/150\n",
      "110/110 [==============================] - 0s 549us/step - loss: 9.6326 - dense_8_loss: 9.0864 - dense_9_loss: 0.5462\n",
      "Epoch 61/150\n",
      "110/110 [==============================] - 0s 547us/step - loss: 9.6328 - dense_8_loss: 9.0865 - dense_9_loss: 0.5464\n",
      "Epoch 62/150\n",
      "110/110 [==============================] - 0s 630us/step - loss: 9.6331 - dense_8_loss: 9.0867 - dense_9_loss: 0.5464\n",
      "Epoch 63/150\n",
      "110/110 [==============================] - 0s 584us/step - loss: 9.6331 - dense_8_loss: 9.0865 - dense_9_loss: 0.5466\n",
      "Epoch 64/150\n",
      "110/110 [==============================] - 0s 544us/step - loss: 9.6327 - dense_8_loss: 9.0864 - dense_9_loss: 0.5463\n",
      "Epoch 65/150\n",
      "110/110 [==============================] - 0s 527us/step - loss: 9.6327 - dense_8_loss: 9.0864 - dense_9_loss: 0.5463\n",
      "Epoch 66/150\n",
      "110/110 [==============================] - 0s 535us/step - loss: 9.6329 - dense_8_loss: 9.0867 - dense_9_loss: 0.5462\n",
      "Epoch 67/150\n",
      "110/110 [==============================] - 0s 530us/step - loss: 9.6334 - dense_8_loss: 9.0870 - dense_9_loss: 0.5465\n",
      "Epoch 68/150\n",
      "110/110 [==============================] - 0s 537us/step - loss: 9.6325 - dense_8_loss: 9.0863 - dense_9_loss: 0.5463\n",
      "Epoch 69/150\n",
      "110/110 [==============================] - 0s 540us/step - loss: 9.6330 - dense_8_loss: 9.0867 - dense_9_loss: 0.5463\n",
      "Epoch 70/150\n",
      "110/110 [==============================] - 0s 555us/step - loss: 9.6329 - dense_8_loss: 9.0866 - dense_9_loss: 0.5463\n",
      "Epoch 71/150\n",
      "110/110 [==============================] - 0s 561us/step - loss: 9.6328 - dense_8_loss: 9.0865 - dense_9_loss: 0.5463\n",
      "Epoch 72/150\n",
      "110/110 [==============================] - 0s 612us/step - loss: 9.6327 - dense_8_loss: 9.0864 - dense_9_loss: 0.5463\n",
      "Epoch 73/150\n",
      "110/110 [==============================] - 0s 568us/step - loss: 9.6327 - dense_8_loss: 9.0863 - dense_9_loss: 0.5463\n",
      "Epoch 74/150\n",
      "110/110 [==============================] - 0s 571us/step - loss: 9.6327 - dense_8_loss: 9.0864 - dense_9_loss: 0.5463\n",
      "Epoch 75/150\n",
      "110/110 [==============================] - 0s 601us/step - loss: 9.6329 - dense_8_loss: 9.0865 - dense_9_loss: 0.5464\n",
      "Epoch 76/150\n",
      "110/110 [==============================] - 0s 553us/step - loss: 9.6327 - dense_8_loss: 9.0864 - dense_9_loss: 0.5463\n",
      "Epoch 77/150\n",
      "110/110 [==============================] - 0s 534us/step - loss: 9.6327 - dense_8_loss: 9.0864 - dense_9_loss: 0.5463\n",
      "Epoch 78/150\n",
      "110/110 [==============================] - 0s 543us/step - loss: 9.6330 - dense_8_loss: 9.0867 - dense_9_loss: 0.5463\n",
      "Epoch 79/150\n",
      "110/110 [==============================] - 0s 557us/step - loss: 9.6329 - dense_8_loss: 9.0866 - dense_9_loss: 0.5462\n",
      "Epoch 80/150\n",
      "110/110 [==============================] - 0s 548us/step - loss: 9.6329 - dense_8_loss: 9.0866 - dense_9_loss: 0.5463\n",
      "Epoch 81/150\n",
      "110/110 [==============================] - 0s 555us/step - loss: 9.6328 - dense_8_loss: 9.0865 - dense_9_loss: 0.5462\n",
      "Epoch 82/150\n",
      "110/110 [==============================] - 0s 547us/step - loss: 9.6327 - dense_8_loss: 9.0864 - dense_9_loss: 0.5463\n",
      "Epoch 83/150\n",
      "110/110 [==============================] - 0s 566us/step - loss: 9.6329 - dense_8_loss: 9.0865 - dense_9_loss: 0.5465\n",
      "Epoch 84/150\n",
      "110/110 [==============================] - 0s 555us/step - loss: 9.6329 - dense_8_loss: 9.0864 - dense_9_loss: 0.5465\n",
      "Epoch 85/150\n",
      "110/110 [==============================] - 0s 565us/step - loss: 9.6326 - dense_8_loss: 9.0864 - dense_9_loss: 0.5462\n",
      "Epoch 86/150\n",
      "110/110 [==============================] - 0s 564us/step - loss: 9.6328 - dense_8_loss: 9.0866 - dense_9_loss: 0.5463\n",
      "Epoch 87/150\n",
      "110/110 [==============================] - 0s 559us/step - loss: 9.6327 - dense_8_loss: 9.0865 - dense_9_loss: 0.5462\n",
      "Epoch 88/150\n",
      "110/110 [==============================] - 0s 555us/step - loss: 9.6327 - dense_8_loss: 9.0865 - dense_9_loss: 0.5462\n",
      "Epoch 89/150\n",
      "110/110 [==============================] - 0s 548us/step - loss: 9.6328 - dense_8_loss: 9.0865 - dense_9_loss: 0.5463\n",
      "Epoch 90/150\n",
      "110/110 [==============================] - 0s 550us/step - loss: 9.6329 - dense_8_loss: 9.0865 - dense_9_loss: 0.5463\n",
      "Epoch 91/150\n",
      "110/110 [==============================] - 0s 546us/step - loss: 9.6329 - dense_8_loss: 9.0867 - dense_9_loss: 0.5462\n",
      "Epoch 92/150\n",
      "110/110 [==============================] - 0s 544us/step - loss: 9.6329 - dense_8_loss: 9.0866 - dense_9_loss: 0.5463\n",
      "Epoch 93/150\n",
      "110/110 [==============================] - 0s 547us/step - loss: 9.6328 - dense_8_loss: 9.0865 - dense_9_loss: 0.5463\n",
      "Epoch 94/150\n",
      "110/110 [==============================] - 0s 544us/step - loss: 9.6332 - dense_8_loss: 9.0868 - dense_9_loss: 0.5463\n",
      "Epoch 95/150\n",
      "110/110 [==============================] - 0s 559us/step - loss: 9.6330 - dense_8_loss: 9.0866 - dense_9_loss: 0.5464\n",
      "Epoch 96/150\n",
      "110/110 [==============================] - 0s 566us/step - loss: 9.6324 - dense_8_loss: 9.0862 - dense_9_loss: 0.5463\n",
      "Epoch 97/150\n",
      "110/110 [==============================] - 0s 547us/step - loss: 9.6329 - dense_8_loss: 9.0865 - dense_9_loss: 0.5463\n",
      "Epoch 98/150\n",
      "110/110 [==============================] - 0s 541us/step - loss: 9.6327 - dense_8_loss: 9.0864 - dense_9_loss: 0.5463\n",
      "Epoch 99/150\n",
      "110/110 [==============================] - 0s 557us/step - loss: 9.6325 - dense_8_loss: 9.0862 - dense_9_loss: 0.5462\n",
      "Epoch 100/150\n",
      "110/110 [==============================] - 0s 537us/step - loss: 9.6326 - dense_8_loss: 9.0864 - dense_9_loss: 0.5462\n",
      "Epoch 101/150\n",
      "110/110 [==============================] - 0s 542us/step - loss: 9.6326 - dense_8_loss: 9.0863 - dense_9_loss: 0.5463\n",
      "Epoch 102/150\n",
      "110/110 [==============================] - 0s 555us/step - loss: 9.6326 - dense_8_loss: 9.0864 - dense_9_loss: 0.5462\n",
      "Epoch 103/150\n",
      "110/110 [==============================] - 0s 556us/step - loss: 9.6328 - dense_8_loss: 9.0865 - dense_9_loss: 0.5463\n",
      "Epoch 104/150\n",
      "110/110 [==============================] - 0s 549us/step - loss: 9.6327 - dense_8_loss: 9.0864 - dense_9_loss: 0.5463\n",
      "Epoch 105/150\n",
      "110/110 [==============================] - 0s 545us/step - loss: 9.6327 - dense_8_loss: 9.0863 - dense_9_loss: 0.5464\n",
      "Epoch 106/150\n",
      "110/110 [==============================] - 0s 544us/step - loss: 9.6325 - dense_8_loss: 9.0862 - dense_9_loss: 0.5463\n",
      "Epoch 107/150\n",
      "110/110 [==============================] - 0s 567us/step - loss: 9.6332 - dense_8_loss: 9.0870 - dense_9_loss: 0.5463\n",
      "Epoch 108/150\n",
      "110/110 [==============================] - 0s 569us/step - loss: 9.6326 - dense_8_loss: 9.0864 - dense_9_loss: 0.5463\n",
      "Epoch 109/150\n",
      "110/110 [==============================] - 0s 576us/step - loss: 9.6328 - dense_8_loss: 9.0864 - dense_9_loss: 0.5464\n",
      "Epoch 110/150\n",
      "110/110 [==============================] - 0s 595us/step - loss: 9.6327 - dense_8_loss: 9.0864 - dense_9_loss: 0.5463\n",
      "Epoch 111/150\n",
      "110/110 [==============================] - 0s 577us/step - loss: 9.6326 - dense_8_loss: 9.0863 - dense_9_loss: 0.5463\n",
      "Epoch 112/150\n",
      "110/110 [==============================] - 0s 606us/step - loss: 9.6328 - dense_8_loss: 9.0865 - dense_9_loss: 0.5463\n",
      "Epoch 113/150\n",
      "110/110 [==============================] - 0s 577us/step - loss: 9.6328 - dense_8_loss: 9.0866 - dense_9_loss: 0.5462\n",
      "Epoch 114/150\n",
      "110/110 [==============================] - 0s 576us/step - loss: 9.6327 - dense_8_loss: 9.0864 - dense_9_loss: 0.5463\n",
      "Epoch 115/150\n",
      "110/110 [==============================] - 0s 567us/step - loss: 9.6328 - dense_8_loss: 9.0865 - dense_9_loss: 0.5463\n",
      "Epoch 116/150\n",
      "110/110 [==============================] - 0s 554us/step - loss: 9.6332 - dense_8_loss: 9.0869 - dense_9_loss: 0.5463\n",
      "Epoch 117/150\n",
      "110/110 [==============================] - 0s 607us/step - loss: 9.6325 - dense_8_loss: 9.0863 - dense_9_loss: 0.5462\n",
      "Epoch 118/150\n",
      "110/110 [==============================] - 0s 640us/step - loss: 9.6326 - dense_8_loss: 9.0864 - dense_9_loss: 0.5462\n",
      "Epoch 119/150\n",
      "110/110 [==============================] - 0s 575us/step - loss: 9.6328 - dense_8_loss: 9.0865 - dense_9_loss: 0.5463\n",
      "Epoch 120/150\n",
      "110/110 [==============================] - 0s 573us/step - loss: 9.6328 - dense_8_loss: 9.0865 - dense_9_loss: 0.5463\n",
      "Epoch 121/150\n",
      "110/110 [==============================] - 0s 572us/step - loss: 9.6329 - dense_8_loss: 9.0866 - dense_9_loss: 0.5463\n",
      "Epoch 122/150\n",
      "110/110 [==============================] - 0s 575us/step - loss: 9.6330 - dense_8_loss: 9.0867 - dense_9_loss: 0.5463\n",
      "Epoch 123/150\n",
      "110/110 [==============================] - 0s 580us/step - loss: 9.6329 - dense_8_loss: 9.0867 - dense_9_loss: 0.5462\n",
      "Epoch 124/150\n",
      "110/110 [==============================] - 0s 562us/step - loss: 9.6324 - dense_8_loss: 9.0862 - dense_9_loss: 0.5462\n",
      "Epoch 125/150\n",
      "110/110 [==============================] - 0s 550us/step - loss: 9.6330 - dense_8_loss: 9.0866 - dense_9_loss: 0.5464\n",
      "Epoch 126/150\n",
      "110/110 [==============================] - 0s 542us/step - loss: 9.6328 - dense_8_loss: 9.0865 - dense_9_loss: 0.5463\n",
      "Epoch 127/150\n",
      "110/110 [==============================] - 0s 545us/step - loss: 9.6326 - dense_8_loss: 9.0864 - dense_9_loss: 0.5463\n",
      "Epoch 128/150\n",
      "110/110 [==============================] - 0s 558us/step - loss: 9.6335 - dense_8_loss: 9.0871 - dense_9_loss: 0.5465\n",
      "Epoch 129/150\n",
      "110/110 [==============================] - 0s 550us/step - loss: 9.6328 - dense_8_loss: 9.0866 - dense_9_loss: 0.5462\n",
      "Epoch 130/150\n",
      "110/110 [==============================] - 0s 544us/step - loss: 9.6328 - dense_8_loss: 9.0864 - dense_9_loss: 0.5464\n",
      "Epoch 131/150\n",
      "110/110 [==============================] - 0s 560us/step - loss: 9.6326 - dense_8_loss: 9.0863 - dense_9_loss: 0.5463\n",
      "Epoch 132/150\n",
      "110/110 [==============================] - 0s 563us/step - loss: 9.6325 - dense_8_loss: 9.0863 - dense_9_loss: 0.5462\n",
      "Epoch 133/150\n",
      "110/110 [==============================] - 0s 566us/step - loss: 9.6336 - dense_8_loss: 9.0870 - dense_9_loss: 0.5466\n",
      "Epoch 134/150\n",
      "110/110 [==============================] - 0s 632us/step - loss: 9.6325 - dense_8_loss: 9.0863 - dense_9_loss: 0.5462\n",
      "Epoch 135/150\n",
      "110/110 [==============================] - 0s 653us/step - loss: 9.6330 - dense_8_loss: 9.0865 - dense_9_loss: 0.5465\n",
      "Epoch 136/150\n",
      "110/110 [==============================] - 0s 665us/step - loss: 9.6331 - dense_8_loss: 9.0868 - dense_9_loss: 0.5462\n",
      "Epoch 137/150\n",
      "110/110 [==============================] - 0s 555us/step - loss: 9.6327 - dense_8_loss: 9.0864 - dense_9_loss: 0.5463\n",
      "Epoch 138/150\n",
      "110/110 [==============================] - 0s 548us/step - loss: 9.6330 - dense_8_loss: 9.0865 - dense_9_loss: 0.5465\n",
      "Epoch 139/150\n",
      "110/110 [==============================] - 0s 555us/step - loss: 9.6334 - dense_8_loss: 9.0871 - dense_9_loss: 0.5463\n",
      "Epoch 140/150\n",
      "110/110 [==============================] - 0s 557us/step - loss: 9.6328 - dense_8_loss: 9.0865 - dense_9_loss: 0.5463\n",
      "Epoch 141/150\n",
      "110/110 [==============================] - 0s 562us/step - loss: 9.6329 - dense_8_loss: 9.0866 - dense_9_loss: 0.5463\n",
      "Epoch 142/150\n",
      "110/110 [==============================] - 0s 555us/step - loss: 9.6327 - dense_8_loss: 9.0865 - dense_9_loss: 0.5462\n",
      "Epoch 143/150\n",
      "110/110 [==============================] - 0s 549us/step - loss: 9.6330 - dense_8_loss: 9.0866 - dense_9_loss: 0.5464\n",
      "Epoch 144/150\n",
      "110/110 [==============================] - 0s 551us/step - loss: 9.6336 - dense_8_loss: 9.0871 - dense_9_loss: 0.5465\n",
      "Epoch 145/150\n",
      "110/110 [==============================] - 0s 565us/step - loss: 9.6327 - dense_8_loss: 9.0864 - dense_9_loss: 0.5463\n",
      "Epoch 146/150\n",
      "110/110 [==============================] - 0s 552us/step - loss: 9.6326 - dense_8_loss: 9.0864 - dense_9_loss: 0.5462\n",
      "Epoch 147/150\n",
      "110/110 [==============================] - 0s 553us/step - loss: 9.6330 - dense_8_loss: 9.0867 - dense_9_loss: 0.5463\n",
      "Epoch 148/150\n",
      "110/110 [==============================] - 0s 543us/step - loss: 9.6326 - dense_8_loss: 9.0863 - dense_9_loss: 0.5463\n",
      "Epoch 149/150\n",
      "110/110 [==============================] - 0s 548us/step - loss: 9.6328 - dense_8_loss: 9.0863 - dense_9_loss: 0.5465\n",
      "Epoch 150/150\n",
      "110/110 [==============================] - 0s 561us/step - loss: 9.6331 - dense_8_loss: 9.0869 - dense_9_loss: 0.5462\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x, [y_regr, y_class], epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.2344221]], dtype=float32),\n",
       " array([0.05782232], dtype=float32),\n",
       " array([[0.14179283]], dtype=float32),\n",
       " array([-0.01255715], dtype=float32)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x142c51d00>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=games_tourney_test[['seed_diff']]\n",
    "y_regr_test=games_tourney_test[['score_diff']]\n",
    "y_class_test=games_tourney_test[['won']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 641us/step - loss: 10.0686 - dense_8_loss: 9.4823 - dense_9_loss: 0.5863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.068556785583496, 9.48228931427002, 0.5862674117088318]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,[y_regr_test,y_class_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred=games_tourney_pred[['seed_diff']]\n",
    "y_regr_pred=games_tourney_pred[['score_diff']]\n",
    "y_class_pred=games_tourney_pred[['won']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ -3.645444  ],\n",
       "        [ 16.10531   ],\n",
       "        [ 18.574154  ],\n",
       "        [ 18.574154  ],\n",
       "        [  0.05782232],\n",
       "        [ -3.645444  ],\n",
       "        [-13.520821  ],\n",
       "        [  1.2922444 ],\n",
       "        [  8.698777  ],\n",
       "        [  9.933199  ],\n",
       "        [  0.05782232],\n",
       "        [  6.229933  ],\n",
       "        [  3.7610884 ],\n",
       "        [  1.2922444 ],\n",
       "        [ 11.167621  ],\n",
       "        [-18.458508  ],\n",
       "        [ -8.583133  ],\n",
       "        [  1.2922444 ],\n",
       "        [ -8.583133  ],\n",
       "        [  1.2922444 ],\n",
       "        [  0.05782232],\n",
       "        [-11.051976  ],\n",
       "        [  3.7610884 ],\n",
       "        [ -1.1765997 ],\n",
       "        [  3.7610884 ],\n",
       "        [  9.933199  ],\n",
       "        [ 11.167621  ],\n",
       "        [  4.9955106 ],\n",
       "        [  8.698777  ],\n",
       "        [ -1.1765997 ],\n",
       "        [ 11.167621  ],\n",
       "        [  9.933199  ],\n",
       "        [ 12.402043  ],\n",
       "        [  6.229933  ]], dtype=float32),\n",
       " array([[0.37064403],\n",
       "        [0.9064518 ],\n",
       "        [0.9322088 ],\n",
       "        [0.9322088 ],\n",
       "        [0.4989104 ],\n",
       "        [0.37064403],\n",
       "        [0.12678236],\n",
       "        [0.54256517],\n",
       "        [0.77221614],\n",
       "        [0.8015324 ],\n",
       "        [0.4989104 ],\n",
       "        [0.70491266],\n",
       "        [0.62732035],\n",
       "        [0.54256517],\n",
       "        [0.8279164 ],\n",
       "        [0.06724235],\n",
       "        [0.22625428],\n",
       "        [0.54256517],\n",
       "        [0.22625428],\n",
       "        [0.54256517],\n",
       "        [0.4989104 ],\n",
       "        [0.17084533],\n",
       "        [0.62732035],\n",
       "        [0.45527226],\n",
       "        [0.62732035],\n",
       "        [0.8015324 ],\n",
       "        [0.8279164 ],\n",
       "        [0.6672493 ],\n",
       "        [0.77221614],\n",
       "        [0.45527226],\n",
       "        [0.8279164 ],\n",
       "        [0.8015324 ],\n",
       "        [0.85144305],\n",
       "        [0.70491266]], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_diff</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4200</th>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4201</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4202</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4209</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4210</th>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4211</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4212</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215</th>\n",
       "      <td>-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4217</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4218</th>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4220</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4222</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4228</th>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4229</th>\n",
       "      <td>-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4230</th>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>-25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score_diff  won\n",
       "4200          -8    0\n",
       "4201          22    1\n",
       "4202          39    1\n",
       "4203          38    1\n",
       "4204          -4    0\n",
       "4205         -12    0\n",
       "4206         -17    0\n",
       "4207          11    1\n",
       "4208           5    1\n",
       "4209           4    1\n",
       "4210          -4    0\n",
       "4211          -1    0\n",
       "4212           8    1\n",
       "4213           2    1\n",
       "4214          10    1\n",
       "4215         -20    0\n",
       "4216           3    1\n",
       "4217          26    1\n",
       "4218          -5    0\n",
       "4219          10    1\n",
       "4220           7    1\n",
       "4221          -6    0\n",
       "4222           3    1\n",
       "4223         -12    0\n",
       "4224          -6    0\n",
       "4225           3    1\n",
       "4226          12    1\n",
       "4227           1    1\n",
       "4228          -3    0\n",
       "4229         -10    0\n",
       "4230          -2    0\n",
       "4231         -25    0\n",
       "4232          24    1\n",
       "4233         -11    0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_regr_pred=games_tourney_pred[['score_diff','won']]\n",
    "y_regr_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
